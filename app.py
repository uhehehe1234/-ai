import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
import pickle
import os
import random as ran


# ================================
# ì§ˆë¬¸ ëª©ë¡
# ================================
questions_list = [
    "ë‚˜ ì˜¤ëŠ˜ ì§„ì§œ ë„ˆë¬´ ì—´ ë°›ëŠ” ì¼ ìˆì—ˆì–´ã… ã… ",
    "í•™êµê°€ê¸° ì‹«ë‹¤;; ê³ 3 ì–¸ì œ ëë‚˜ëƒã… ã… ",
    "ë‚˜ OOì´ë‘ ì¹œí•´ì§€ê³  ì‹¶ì€ë° ë§ ê±¸ì–´ë³¼ê¹Œ?",
    "ë‚˜ ë°©ê¸ˆ ê¸¸ì—ì„œ ìë¹ ì¡Œë‹¤;;",
    "ìˆ˜ëŠ¥ 200ì¼ ê¹¨ì¡Œë‹¤.... ì–´ë–¡í•˜ëƒ...ã…‹ã…‹",
    "ì˜¤ëŠ˜ ìŒ¤í•œí…Œ ã…ˆã„´ ê¹¨ì¡Œë‹¤...ã…‹ã…‹",
    "ì˜¤ëŠ˜ í•˜ë£¨ ì–´ë• ëƒ?",
    "ì•¼ì•¼ OOì•„ (ë³¸ì¸ì„ ë¶€ë¥´ëŠ” ìƒí™©)"]

questions_extra_list = [
    "ë„ˆì—ê²Œ ë§í• ê²Œ ìˆì–´.. ì‚¬ì‹¤ ë‚´ê°€ ì´ˆëŠ¥ë ¥ì´ ìˆì–´..",
    "í˜¹ì‹œ ë„ˆ.. ì€í•˜ê³„ì—ì„œ ì˜¨ ì™¸ê³„ì¸ì´ì•¼...?",
]

questions = []

# ================================
# ëª¨ë¸ ë° ë¦¬ì†ŒìŠ¤ ë¶ˆëŸ¬ì˜¤ê¸°
# ================================
@st.cache_resource
def load_resources():
    model = load_model("ë§íˆ¬í•™ìŠµëª¨ë¸.h5") 
    with open("tokenizer.pkl", "rb") as f:
        tokenizer = pickle.load(f)
    with open("label_encoder.pkl", "rb") as f:
        label_encoder = pickle.load(f)  
    return model, tokenizer, label_encoder

model, tokenizer, label_encoder = load_resources()

# ================================
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# ================================
if "started" not in st.session_state:
    st.session_state.started = False
if "step" not in st.session_state:
    st.session_state.step = 0
if "responses" not in st.session_state:
    st.session_state.responses = []
if "predictions" not in st.session_state:
    st.session_state.predictions = []
if "questions_model" not in st.session_state:
    st.session_state.questions_model = []
if "result_maltu" not in st.session_state:
    st.session_state.result_maltu = []

# ================================
# íƒ€ì´í‹€ ë° ì†Œê°œ
# ================================
st.markdown("<h1 style='text-align: center;'>ğŸ’¬ ì±„íŒ… ë§íˆ¬ ë¶„ì„ê¸°</h1>", unsafe_allow_html=True)
st.markdown("<h4 style='text-align: center;'>ì•„ë˜ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”!</h4>", unsafe_allow_html=True)
st.markdown("---")

# ================================
# ì‹œì‘ í™”ë©´ â†’ ë¶„ì„ ì‹œì‘ ë²„íŠ¼
# ================================
if not st.session_state.started:
    if st.button("ğŸš€ ë¶„ì„ ì‹œì‘"):
        st.session_state.started = True
        numbers = [0,1,2,3,4,5,6,7]
        number_sample = ran.sample(numbers, 3)
        questions.append(questions_list[int(number_sample[0])])
        questions.append(questions_list[int(number_sample[1])])
        questions.append(questions_list[int(number_sample[2])])
        st.session_state.questions_model.append(questions[0])
        st.session_state.questions_model.append(questions[1])
        st.session_state.questions_model.append(questions[2])
        print(questions)
        st.rerun()
    st.stop()

# ================================
# ì§ˆë¬¸ ë° ì‘ë‹µ íë¦„
# ================================
total_steps = len(st.session_state.questions_model)
step = st.session_state.step
if step < total_steps:
    st.markdown(f"### ì§ˆë¬¸ {step + 1}: {st.session_state.questions_model[step]}")
    user_input = st.text_input("ë‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”:", key=f"input_{step}")

    if st.button("âœ… ì‘ë‹µ ì™„ë£Œ"):
        if user_input.strip() != "":
            # ì‘ë‹µ ì €ì¥
            st.session_state.responses.append(user_input)

            # ì˜ˆì¸¡
            seq = tokenizer.texts_to_sequences([user_input])
            padded = pad_sequences(seq, maxlen=30, padding='post')
            pred = model.predict(padded)
            st.session_state.predictions.append(pred[0])

            # ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ì´ë™
            st.session_state.step += 1
            st.rerun()
        else:
            st.warning("ë‹µë³€ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
else:
    # ================================
    # ìµœì¢… ê²°ê³¼ ì¶œë ¥
    # ================================
    st.markdown("## ğŸ“Š ë¶„ì„ ê²°ê³¼")
    for idx, question in enumerate(st.session_state.predictions):
        response = st.session_state.responses[idx]
        prediction = st.session_state.predictions[idx]
        label = label_encoder.inverse_transform([np.argmax(prediction)])[0]
        confidence = np.max(prediction) * 100
        st.session_state.result_maltu.append(str(label))
        

        st.markdown(f"### {idx + 1}. {st.session_state.questions_model[idx]}")
        st.markdown(f"- âœï¸ ë‹¹ì‹ ì˜ ë‹µ: `{response}`")
        st.markdown(f"- ğŸ” ì˜ˆì¸¡ëœ ë§íˆ¬ ìŠ¤íƒ€ì¼: **{label}** ({confidence:.2f}%)")

        print(label)

        st.header(f"{label}") #ì´ì½¤ì‹œì˜ ì¡°ì–¸

        if label == "ì¹œê·¼í˜•":
            st.markdown("<ì´ì½¤ì‹œì˜ ì„¤ëª…>")
            st.markdown("ë‹¹ì‹ ì€ [ì¹œê·¼í˜•] ì…ë‹ˆë‹¤!")

        elif label == " ì¹œê·¼í˜•":
            st.markdown("<ì´ì½¤ì‹œì˜ ì„¤ëª…>")
            st.markdown("ë‹¹ì‹ ì€ [ì¹œê·¼í˜•] ì…ë‹ˆë‹¤!")

        elif label == "ê·€ì°®ìŒí˜•":
            st.markdown("<ì´ì½¤ì‹œì˜ ì„¤ëª…>")
            st.markdown("ë‹¹ì‹ ì€ [ê·€ì°®ìŒí˜•] ì…ë‹ˆë‹¤!")

        elif label == "ìš•ìŸì´í˜•":
            st.markdown("<ì´ì½¤ì‹œì˜ ì„¤ëª…>")
            st.markdown("ë‹¹ì‹ ì€ [ìš•ìŸì´í˜•] ì…ë‹ˆë‹¤!")

        elif label == "ê¹Œì¹ í˜•":
            st.markdown("<ì´ì½¤ì‹œì˜ ì„¤ëª…>")
            st.markdown("ë‹¹ì‹ ì€ [ê¹Œì¹ í˜•] ì…ë‹ˆë‹¤!")

        elif label == "ê³µê°í˜•":
            st.markdown("<ì´ì½¤ì‹œì˜ ì„¤ëª…>")
            st.markdown("ë‹¹ì‹ ì€ [ê³µê°í˜•] ì…ë‹ˆë‹¤!")

        st.progress(int(confidence))
        st.markdown("---")

    st.header("1.",str(st.session_state.result_maltu[0]))
    st.header("2.",str(st.session_state.result_maltu[0]))
    st.header("3.",str(st.session_state.result_maltu[0]))


    # ================================
    # í…ŒìŠ¤íŠ¸ ì¬ì‹œì‘
    # ================================
    if st.button("ğŸ”„ ë‹¤ì‹œ í…ŒìŠ¤íŠ¸í•˜ê¸°"):
        for key in ["started", "step", "responses", "predictions","questions_model"]:
            del st.session_state[key]
            questions.clear()
        st.rerun()


